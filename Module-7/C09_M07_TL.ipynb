{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq2aBGJ3eZg"
      },
      "source": [
        "# MLP for Regression and Classificaiton using both PyTorch and Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W0UFgQz3l9K"
      },
      "source": [
        "### Step 0: Set Up the Environment\n",
        "Ensure you have PySpark, PyTorch, and other necessary libraries installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "x2jK-moc3dMC"
      },
      "outputs": [],
      "source": [
        "# ! pip install pyspark torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tiVmq72dUMG-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from keras import layers, Input\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeVRwwV04gSP"
      },
      "source": [
        "## Part 1: MLP for Regression – Predicting California Housing Prices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13jZ3NWm3iq9"
      },
      "source": [
        "### Step 1: Load and Prepare the Data\n",
        "* Load the California housing dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame for distributed processing.\n",
        "* Assemble feature vectors for PySpark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oHTz8PN83vOi"
      },
      "outputs": [],
      "source": [
        "# Load and Normalize California Housing Data\n",
        "housing = fetch_california_housing()\n",
        "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df_housing['target'] = housing.target  # Apply log transformation\n",
        "\n",
        "X = df_housing[housing.feature_names].values\n",
        "y = df_housing['target'].values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXoORM4A3wlC"
      },
      "source": [
        "### Step 2: [PyTorch] Convert Spark Data to PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_cGg8VbJ4z7H"
      },
      "outputs": [],
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI-uZHPj48m6"
      },
      "source": [
        "### Step 3: [PyTorch] Build the MLP Model for Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0MPNiQx55D0U"
      },
      "outputs": [],
      "source": [
        "# Define MLP architecture to match TensorFlow\n",
        "class MLPRegressor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLPRegressor, self).__init__()\n",
        "        # First layer with BatchNorm\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Second layer with ReLU and then Dropout (matching TensorFlow placement)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)  # Moved dropout after ReLU to match TensorFlow\n",
        "        )\n",
        "        # Output layer\n",
        "        self.layer3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "pt_model_regression = MLPRegressor(X_train.shape[1])\n",
        "\n",
        "# Use Adam optimizer with default settings to match TensorFlow\n",
        "# TensorFlow default Adam: lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7\n",
        "optimizer = optim.Adam(\n",
        "    pt_model_regression.parameters(),\n",
        "    lr=0.001,  # Default TensorFlow learning rate\n",
        "    betas=(0.9, 0.999),  # Default betas\n",
        "    eps=1e-8  # PyTorch default epsilon (slightly different from TF)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l1N6rY5F6g"
      },
      "source": [
        "### Step 4: [PyTorch] Train the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkHJcyrO5Jk-",
        "outputId": "a2d5b940-9078-4c3d-8acf-0ceefad9412d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 0.9534\n",
            "Epoch [11/50], Loss: 0.4374\n",
            "Epoch [21/50], Loss: 0.3995\n",
            "Epoch [31/50], Loss: 0.3900\n",
            "Epoch [41/50], Loss: 0.3798\n",
            "Epoch [50/50], Loss: 0.3785\n"
          ]
        }
      ],
      "source": [
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Create DataLoader for mini-batch training\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Match TF batch size=32\n",
        "\n",
        "# Training loop with mini-batches (50 epochs to match TensorFlow)\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Mini-batch training\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = pt_model_regression(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics (similar to TensorFlow verbose=1)\n",
        "    if epoch % 10 == 0 or epoch == num_epochs-1:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASWz5pn_5LzS"
      },
      "source": [
        "### Step 5: [PyTorch] Evaluate the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2mKp1dp5lTZ",
        "outputId": "626193f7-594d-4fa5-ecce-d9837cdd7568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Mean Squared Error: 0.4117\n",
            "Test Mean Absolute Error: 0.4383\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = pt_model_regression(X_test_t)\n",
        "    mse_loss = criterion(predictions, y_test_t)\n",
        "    mae_loss = nn.L1Loss()(predictions, y_test_t)  # Calculate MAE to match TensorFlow metrics\n",
        "\n",
        "print(f'Test Mean Squared Error: {mse_loss.item():.4f}')\n",
        "print(f'Test Mean Absolute Error: {mae_loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6b_D0Tf5oyv"
      },
      "source": [
        "### Step 6: [PyTorch] Make Predictions with the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZBlDiRG5rlN",
        "outputId": "004aade6-5725-44f3-ff6d-537da37254c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted House Price: 3.95\n"
          ]
        }
      ],
      "source": [
        "# Make predictions with scaled input (matching TensorFlow's approach)\n",
        "sample_input_np = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input_scaled = scaler.transform(sample_input_np)  # Apply scaling\n",
        "sample_input_t = torch.tensor(sample_input_scaled, dtype=torch.float32)\n",
        "\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    pt_prediction = pt_model_regression(sample_input_t).item()\n",
        "\n",
        "print(f'Predicted House Price: {pt_prediction:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izc9GcLd6_D-"
      },
      "source": [
        "### Step 7: [TensorFlow] Build the MLP Model for Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "-MmwmfrC7BXN",
        "outputId": "24e32411-035d-4da1-c8ec-5ad092cbe1bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\craig\\anaconda3\\envs\\ml-env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define MLP architecture\n",
        "tf_model_regression = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "tf_model_regression.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Display model summary\n",
        "tf_model_regression.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBnx133N7IbV"
      },
      "source": [
        "### Step 8: [TensorFlow] Train the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WSzTOKnx7OoX",
        "outputId": "4c9bf0a6-e7ec-4e28-f0dc-9d20b0b14cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5204 - mae: 0.9177 - val_loss: 0.5018 - val_mae: 0.4880\n",
            "Epoch 2/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.6610 - mae: 0.5957 - val_loss: 0.5604 - val_mae: 0.5350\n",
            "Epoch 3/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.5509 - mae: 0.5363 - val_loss: 0.4975 - val_mae: 0.5005\n",
            "Epoch 4/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.4809 - mae: 0.4991 - val_loss: 0.5079 - val_mae: 0.5049\n",
            "Epoch 5/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.4715 - mae: 0.4915 - val_loss: 0.4414 - val_mae: 0.4625\n",
            "Epoch 6/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.4334 - mae: 0.4706 - val_loss: 0.4019 - val_mae: 0.4260\n",
            "Epoch 7/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.4436 - mae: 0.4713 - val_loss: 0.4123 - val_mae: 0.4401\n",
            "Epoch 8/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.4315 - mae: 0.4655 - val_loss: 0.3333 - val_mae: 0.3950\n",
            "Epoch 9/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.4047 - mae: 0.4529 - val_loss: 0.3432 - val_mae: 0.4112\n",
            "Epoch 10/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.3902 - mae: 0.4487 - val_loss: 0.3771 - val_mae: 0.4141\n",
            "Epoch 11/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.3924 - mae: 0.4444 - val_loss: 0.3745 - val_mae: 0.4251\n",
            "Epoch 12/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.3954 - mae: 0.4464 - val_loss: 0.3740 - val_mae: 0.4149\n",
            "Epoch 13/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.3881 - mae: 0.4404 - val_loss: 0.3630 - val_mae: 0.4202\n",
            "Epoch 14/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.3857 - mae: 0.4413 - val_loss: 0.3446 - val_mae: 0.3980\n",
            "Epoch 15/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.3745 - mae: 0.4332 - val_loss: 0.3508 - val_mae: 0.4211\n",
            "Epoch 16/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.3699 - mae: 0.4335 - val_loss: 0.3967 - val_mae: 0.4382\n",
            "Epoch 17/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.3729 - mae: 0.4337 - val_loss: 0.3347 - val_mae: 0.4030\n",
            "Epoch 18/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.3862 - mae: 0.4420 - val_loss: 0.3902 - val_mae: 0.4367\n",
            "Epoch 19/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.3552 - mae: 0.4246 - val_loss: 0.3885 - val_mae: 0.4322\n",
            "Epoch 20/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.3557 - mae: 0.4241 - val_loss: 0.3500 - val_mae: 0.4174\n",
            "Epoch 21/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.3570 - mae: 0.4236 - val_loss: 0.3719 - val_mae: 0.4146\n",
            "Epoch 22/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.3652 - mae: 0.4264 - val_loss: 0.3742 - val_mae: 0.4342\n",
            "Epoch 23/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.3729 - mae: 0.4301 - val_loss: 0.3421 - val_mae: 0.4013\n",
            "Epoch 24/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.3475 - mae: 0.4178 - val_loss: 0.3710 - val_mae: 0.4209\n",
            "Epoch 25/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.3666 - mae: 0.4291 - val_loss: 0.3492 - val_mae: 0.4206\n",
            "Epoch 26/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.3595 - mae: 0.4272 - val_loss: 0.3739 - val_mae: 0.4401\n",
            "Epoch 27/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.3500 - mae: 0.4212 - val_loss: 0.4125 - val_mae: 0.4430\n",
            "Epoch 28/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.3520 - mae: 0.4190 - val_loss: 0.3150 - val_mae: 0.3843\n",
            "Epoch 29/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.3500 - mae: 0.4201 - val_loss: 0.3502 - val_mae: 0.4079\n",
            "Epoch 30/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.3448 - mae: 0.4219 - val_loss: 0.3467 - val_mae: 0.4157\n",
            "Epoch 31/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.3435 - mae: 0.4138 - val_loss: 0.3500 - val_mae: 0.4264\n",
            "Epoch 32/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.3378 - mae: 0.4165 - val_loss: 0.3517 - val_mae: 0.4174\n",
            "Epoch 33/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.3438 - mae: 0.4171 - val_loss: 0.3348 - val_mae: 0.4122\n",
            "Epoch 34/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.3498 - mae: 0.4234 - val_loss: 0.3382 - val_mae: 0.4006\n",
            "Epoch 35/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.3482 - mae: 0.4164 - val_loss: 0.3235 - val_mae: 0.4061\n",
            "Epoch 36/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.3378 - mae: 0.4138 - val_loss: 0.3228 - val_mae: 0.4065\n",
            "Epoch 37/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.3401 - mae: 0.4144 - val_loss: 0.3279 - val_mae: 0.4121\n",
            "Epoch 38/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.3359 - mae: 0.4155 - val_loss: 0.3716 - val_mae: 0.4310\n",
            "Epoch 39/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.3361 - mae: 0.4117 - val_loss: 0.3375 - val_mae: 0.4148\n",
            "Epoch 40/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.3390 - mae: 0.4122 - val_loss: 0.3004 - val_mae: 0.3866\n",
            "Epoch 41/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3337 - mae: 0.4117 - val_loss: 0.3161 - val_mae: 0.3939\n",
            "Epoch 42/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.3425 - mae: 0.4138 - val_loss: 0.3491 - val_mae: 0.4129\n",
            "Epoch 43/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.3433 - mae: 0.4121 - val_loss: 0.2967 - val_mae: 0.3776\n",
            "Epoch 44/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.3292 - mae: 0.4104 - val_loss: 0.3127 - val_mae: 0.4023\n",
            "Epoch 45/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3325 - mae: 0.4077 - val_loss: 0.3206 - val_mae: 0.3941\n",
            "Epoch 46/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.3334 - mae: 0.4128 - val_loss: 0.3064 - val_mae: 0.3883\n",
            "Epoch 47/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - loss: 0.3309 - mae: 0.4103 - val_loss: 0.3590 - val_mae: 0.4217\n",
            "Epoch 48/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.3301 - mae: 0.4124 - val_loss: 0.3087 - val_mae: 0.3936\n",
            "Epoch 49/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.3355 - mae: 0.4159 - val_loss: 0.3073 - val_mae: 0.3953\n",
            "Epoch 50/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.3180 - mae: 0.4046 - val_loss: 0.3272 - val_mae: 0.4166\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "tf_history_regression = tf_model_regression.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOnyOGV7PU7"
      },
      "source": [
        "### Step 9: [TensorFlow] Evaluate the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaiR3tuf7S5h",
        "outputId": "a378a456-e250-44ff-a69e-c224db9bcaf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.3207 - mae: 0.4148\n",
            "Test Mean Absolute Error: 0.4166\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "loss, mae = tf_model_regression.evaluate(X_test, y_test)\n",
        "print(f\"Test Mean Absolute Error: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puK16Lpi7Ua8"
      },
      "source": [
        "### Step 10:[TensorFlow] Make Predictions with the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkiJibE7ae5",
        "outputId": "16252cc5-8c8d-4081-f948-1d8e8dfaf0a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "Predicted House Price: 2.83\n"
          ]
        }
      ],
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input = scaler.transform(sample_input)  # Apply same scaling\n",
        "\n",
        "# Make prediction\n",
        "predicted_price = tf_model_regression.predict(sample_input)[0, 0]\n",
        "print(f\"Predicted House Price: {predicted_price:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGT_gcbwjO1p"
      },
      "source": [
        "## Part 2: MLP for Classification – Predicting Iris Flower Species"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpmSIlTOjPcg"
      },
      "source": [
        "### Step 11: Load and Prepare the Data\n",
        "* Load the Iris dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame.\n",
        "* Encode categorical labels and assemble features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kvmpZTIdjWjZ"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df_iris['label'] = iris.target\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = df_iris[iris.feature_names].values\n",
        "y = df_iris['label'].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z99ffMINjYT5"
      },
      "source": [
        "### Step 12: (PyTorch) Convert Spark Data to PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jlc8YIovje7d"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)  # Long tensor for classification\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydzx9We9jhl2"
      },
      "source": [
        "### Step 13: (PyTorch) Build the MLP Model for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HX-39tkXjj1_"
      },
      "outputs": [],
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_t.shape[1]\n",
        "hidden_size = 16\n",
        "output_size = len(iris.target_names)\n",
        "\n",
        "pt_model_classification = MLPClassifier(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(pt_model_classification.parameters(), lr=0.01)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_G4WcvJjl57"
      },
      "source": [
        "### Step 14: (PyTorch) Train the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrNI2uYtjnnt",
        "outputId": "3ac14a70-2dcb-411f-b55d-994084dea9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/100], Loss: 1.0945\n",
            "Epoch [10/100], Loss: 0.9142\n",
            "Epoch [20/100], Loss: 0.8036\n",
            "Epoch [30/100], Loss: 0.7375\n",
            "Epoch [40/100], Loss: 0.6997\n",
            "Epoch [50/100], Loss: 0.6680\n",
            "Epoch [60/100], Loss: 0.6362\n",
            "Epoch [70/100], Loss: 0.6146\n",
            "Epoch [80/100], Loss: 0.6019\n",
            "Epoch [90/100], Loss: 0.5944\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = pt_model_classification(X_train_t)\n",
        "    loss = criterion(outputs, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF9t_-Ykjt7s"
      },
      "source": [
        "### Step 15: (PyTorch) Evaluate the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pRkJ9flj3DS",
        "outputId": "872af9f5-83f7-4e7c-95e7-9f3126ad2f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy: 0.9667\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    predictions = pt_model_classification(X_test_t)\n",
        "    predicted_labels = torch.argmax(predictions, axis=1)\n",
        "    accuracy = (predicted_labels == y_test_t).sum().item() / y_test_t.size(0)\n",
        "\n",
        "print(f'Classification Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY0yhjstj60B"
      },
      "source": [
        "### Step 16: (PyTorch) Make Predictions with the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At8UV4Zfj_z8",
        "outputId": "ebcc0099-5bec-462a-b62c-37868a79dbd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: virginica\n"
          ]
        }
      ],
      "source": [
        "sample_input = torch.tensor([[6.7, 3.1, 4.9, 1.5]])  # Example from dataset\n",
        "with torch.no_grad():\n",
        "    prediction = pt_model_classification(sample_input)\n",
        "    predicted_class = torch.argmax(prediction, axis=1).item()\n",
        "\n",
        "print(f'Predicted Class: {iris.target_names[predicted_class]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QSJHKRJkDGf"
      },
      "source": [
        "### Step 17: (TensorFlow) Build the MLP Model for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ImEuEZdlkHPM",
        "outputId": "3bc9877b-8641-4d42-f8c5-10f71aad3f91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Create a new model (to avoid sharing weights)\n",
        "tf_model_classification = keras.Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Define input layer\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile with categorical crossentropy\n",
        "tf_model_classification.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "tf_model_classification.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZnTxlzfkJsf"
      },
      "source": [
        "### Step 18: (TensorFlow) Train the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUqY1KIDkQqR",
        "outputId": "70842006-61fd-4d7a-9375-374b4043a405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1082 - loss: 1.0891 - val_accuracy: 0.3000 - val_loss: 1.0683\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2602 - loss: 1.0589 - val_accuracy: 0.3667 - val_loss: 1.0337\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2629 - loss: 1.0357 - val_accuracy: 0.4000 - val_loss: 1.0026\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3025 - loss: 1.0174 - val_accuracy: 0.6333 - val_loss: 0.9730\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5630 - loss: 0.9738 - val_accuracy: 0.6333 - val_loss: 0.9419\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5770 - loss: 0.9465 - val_accuracy: 0.7000 - val_loss: 0.9075\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6610 - loss: 0.9234 - val_accuracy: 0.8000 - val_loss: 0.8712\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7757 - loss: 0.8969 - val_accuracy: 0.9000 - val_loss: 0.8346\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.8620 - val_accuracy: 0.9333 - val_loss: 0.7965\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.7995 - val_accuracy: 0.9333 - val_loss: 0.7569\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.7668 - val_accuracy: 0.9000 - val_loss: 0.7162\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 0.7574 - val_accuracy: 0.9000 - val_loss: 0.6767\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.7309 - val_accuracy: 0.9000 - val_loss: 0.6374\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8016 - loss: 0.7185 - val_accuracy: 0.9000 - val_loss: 0.5983\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.6500 - val_accuracy: 0.9000 - val_loss: 0.5594\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7902 - loss: 0.6309 - val_accuracy: 0.9000 - val_loss: 0.5240\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.5800 - val_accuracy: 0.9000 - val_loss: 0.4918\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.5404 - val_accuracy: 0.9000 - val_loss: 0.4614\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.5227 - val_accuracy: 0.9000 - val_loss: 0.4352\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.4659 - val_accuracy: 0.9000 - val_loss: 0.4110\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7750 - loss: 0.5120 - val_accuracy: 0.9000 - val_loss: 0.3892\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8378 - loss: 0.4636 - val_accuracy: 0.9000 - val_loss: 0.3689\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8122 - loss: 0.4422 - val_accuracy: 0.9000 - val_loss: 0.3504\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.3799 - val_accuracy: 0.9000 - val_loss: 0.3342\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8588 - loss: 0.3911 - val_accuracy: 0.9333 - val_loss: 0.3195\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8539 - loss: 0.3827 - val_accuracy: 0.9333 - val_loss: 0.3062\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8300 - loss: 0.3881 - val_accuracy: 0.9333 - val_loss: 0.2937\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8359 - loss: 0.3887 - val_accuracy: 0.9333 - val_loss: 0.2827\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8855 - loss: 0.3302 - val_accuracy: 0.9333 - val_loss: 0.2720\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8800 - loss: 0.3579 - val_accuracy: 0.9333 - val_loss: 0.2618\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8628 - loss: 0.3213 - val_accuracy: 0.9333 - val_loss: 0.2517\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.2846 - val_accuracy: 0.9333 - val_loss: 0.2419\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8990 - loss: 0.2917 - val_accuracy: 0.9333 - val_loss: 0.2335\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.3131 - val_accuracy: 0.9333 - val_loss: 0.2248\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.2984 - val_accuracy: 0.9333 - val_loss: 0.2173\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9204 - loss: 0.2690 - val_accuracy: 0.9667 - val_loss: 0.2099\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2669 - val_accuracy: 0.9667 - val_loss: 0.2032\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.2495 - val_accuracy: 0.9667 - val_loss: 0.1968\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9504 - loss: 0.2494 - val_accuracy: 0.9667 - val_loss: 0.1909\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.2522 - val_accuracy: 0.9667 - val_loss: 0.1853\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8909 - loss: 0.2591 - val_accuracy: 0.9667 - val_loss: 0.1799\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9283 - loss: 0.2298 - val_accuracy: 0.9667 - val_loss: 0.1747\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9573 - loss: 0.1903 - val_accuracy: 0.9667 - val_loss: 0.1700\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2395 - val_accuracy: 0.9667 - val_loss: 0.1661\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.2555 - val_accuracy: 0.9667 - val_loss: 0.1619\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2155 - val_accuracy: 0.9667 - val_loss: 0.1565\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.1829 - val_accuracy: 0.9667 - val_loss: 0.1541\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9628 - loss: 0.1759 - val_accuracy: 0.9667 - val_loss: 0.1494\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9444 - loss: 0.1974 - val_accuracy: 0.9667 - val_loss: 0.1469\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2073 - val_accuracy: 0.9667 - val_loss: 0.1432\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9391 - loss: 0.2142 - val_accuracy: 0.9667 - val_loss: 0.1389\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.1877 - val_accuracy: 0.9667 - val_loss: 0.1358\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9398 - loss: 0.1680 - val_accuracy: 0.9667 - val_loss: 0.1331\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1610 - val_accuracy: 0.9667 - val_loss: 0.1295\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9370 - loss: 0.1685 - val_accuracy: 0.9667 - val_loss: 0.1263\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9374 - loss: 0.1942 - val_accuracy: 0.9667 - val_loss: 0.1232\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 0.1803 - val_accuracy: 0.9667 - val_loss: 0.1202\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.1910 - val_accuracy: 0.9667 - val_loss: 0.1186\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9581 - loss: 0.1776 - val_accuracy: 0.9667 - val_loss: 0.1154\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9123 - loss: 0.1822 - val_accuracy: 0.9667 - val_loss: 0.1133\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.1479 - val_accuracy: 0.9667 - val_loss: 0.1101\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.1168 - val_accuracy: 0.9667 - val_loss: 0.1089\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9608 - loss: 0.1386 - val_accuracy: 0.9667 - val_loss: 0.1061\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9626 - loss: 0.1351 - val_accuracy: 0.9667 - val_loss: 0.1047\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9736 - loss: 0.1262 - val_accuracy: 0.9667 - val_loss: 0.1039\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.1526 - val_accuracy: 0.9667 - val_loss: 0.1002\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9443 - loss: 0.1534 - val_accuracy: 1.0000 - val_loss: 0.0980\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.1335 - val_accuracy: 1.0000 - val_loss: 0.0965\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.1309 - val_accuracy: 1.0000 - val_loss: 0.0948\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.1344 - val_accuracy: 1.0000 - val_loss: 0.0937\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9475 - loss: 0.1397 - val_accuracy: 1.0000 - val_loss: 0.0930\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9436 - loss: 0.1494 - val_accuracy: 1.0000 - val_loss: 0.0899\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9687 - loss: 0.0985 - val_accuracy: 1.0000 - val_loss: 0.0866\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.1230 - val_accuracy: 1.0000 - val_loss: 0.0841\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.1080 - val_accuracy: 1.0000 - val_loss: 0.0869\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9668 - loss: 0.1164 - val_accuracy: 1.0000 - val_loss: 0.0879\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.1258 - val_accuracy: 1.0000 - val_loss: 0.0842\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.1255 - val_accuracy: 1.0000 - val_loss: 0.0823\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9722 - loss: 0.0928 - val_accuracy: 1.0000 - val_loss: 0.0821\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9687 - loss: 0.0945 - val_accuracy: 1.0000 - val_loss: 0.0812\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9705 - loss: 0.0965 - val_accuracy: 1.0000 - val_loss: 0.0800\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.1058 - val_accuracy: 1.0000 - val_loss: 0.0772\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9496 - loss: 0.1273 - val_accuracy: 1.0000 - val_loss: 0.0747\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9603 - loss: 0.1106 - val_accuracy: 1.0000 - val_loss: 0.0735\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.1014 - val_accuracy: 1.0000 - val_loss: 0.0740\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.1007 - val_accuracy: 1.0000 - val_loss: 0.0709\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.0937 - val_accuracy: 1.0000 - val_loss: 0.0694\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9579 - loss: 0.0998 - val_accuracy: 1.0000 - val_loss: 0.0693\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9391 - loss: 0.1156 - val_accuracy: 1.0000 - val_loss: 0.0688\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9386 - loss: 0.1174 - val_accuracy: 1.0000 - val_loss: 0.0695\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0890 - val_accuracy: 1.0000 - val_loss: 0.0679\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9776 - loss: 0.0943 - val_accuracy: 1.0000 - val_loss: 0.0689\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9273 - loss: 0.1272 - val_accuracy: 1.0000 - val_loss: 0.0655\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9673 - loss: 0.0757 - val_accuracy: 1.0000 - val_loss: 0.0642\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9310 - loss: 0.1417 - val_accuracy: 1.0000 - val_loss: 0.0647\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.0927 - val_accuracy: 1.0000 - val_loss: 0.0634\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9677 - loss: 0.0868 - val_accuracy: 1.0000 - val_loss: 0.0666\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0644 - val_accuracy: 1.0000 - val_loss: 0.0645\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.1067 - val_accuracy: 1.0000 - val_loss: 0.0610\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.1044 - val_accuracy: 1.0000 - val_loss: 0.0593\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history_classification = tf_model_classification.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55bD72DDkTZF"
      },
      "source": [
        "### Step 19: (TensorFlow) Evaluate the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gq3bLY5kZJ-",
        "outputId": "cdef52fe-faca-4392-9605-03c15805d893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0593\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "# Use one-hot encoded labels for evaluation\n",
        "loss, accuracy = tf_model_classification.evaluate(X_test, y_test_one_hot)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LtG1TMOkbye"
      },
      "source": [
        "### Step 20: Make Predictions with the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_xw_4XskcJS",
        "outputId": "665c9d83-fe73-4d66-9ecb-0b932a28ef60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Predicted Class: virginica\n"
          ]
        }
      ],
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[6.7, 3.1, 4.9, 1.5]])  # Example from Iris dataset\n",
        "\n",
        "# Make prediction\n",
        "tf_model_classification_prediction = tf_model_classification.predict(sample_input)\n",
        "tf_predicted_class = np.argmax(tf_model_classification_prediction, axis=1)[0]\n",
        "\n",
        "# Output predicted class\n",
        "print(f\"Predicted Class: {iris.target_names[predicted_class]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (ml-env)",
      "language": "python",
      "name": "ml-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
